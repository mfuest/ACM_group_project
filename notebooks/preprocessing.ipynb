{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing Notebook\n",
        "\n",
        "This notebook loads scraped Reddit data, performs cleaning and preprocessing,\n",
        "and creates a unified dataset for analysis.\n",
        "\n",
        "## Steps:\n",
        "1. Load all scraped CSV files\n",
        "2. Merge into a single DataFrame\n",
        "3. Text cleaning (lowercase, URL removal)\n",
        "4. Create full_text column (title + selftext)\n",
        "5. Mark political posts\n",
        "6. Export cleaned dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Set project root\n",
        "PROJECT_ROOT = Path().resolve().parent\n",
        "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
        "DATA_CLEAN = PROJECT_ROOT / \"data\" / \"clean\"\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Raw data directory: {DATA_RAW}\")\n",
        "print(f\"Clean data directory: {DATA_CLEAN}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load All Scraped CSV Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all raw CSV files\n",
        "raw_files = list(DATA_RAW.glob(\"*.csv\"))\n",
        "print(f\"Found {len(raw_files)} raw data files:\")\n",
        "for f in sorted(raw_files):\n",
        "    print(f\"  - {f.name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all raw CSV files into a list of DataFrames\n",
        "dataframes = []\n",
        "\n",
        "for file_path in sorted(raw_files):\n",
        "    # Extract country and phase from filename (e.g., \"germany_pre_euro.csv\")\n",
        "    filename = file_path.stem  # Remove .csv extension\n",
        "    parts = filename.split(\"_\")\n",
        "    \n",
        "    if len(parts) >= 2:\n",
        "        country = parts[0]\n",
        "        phase = \"_\".join(parts[1:])  # Handle multi-word phases\n",
        "        \n",
        "        try:\n",
        "            df = pd.read_csv(file_path)\n",
        "            df[\"country\"] = country\n",
        "            df[\"phase\"] = phase\n",
        "            df[\"source_file\"] = file_path.name\n",
        "            dataframes.append(df)\n",
        "            print(f\"Loaded {len(df)} rows from {file_path.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path.name}: {e}\")\n",
        "\n",
        "print(f\"\\nTotal files loaded: {len(dataframes)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Merge into Single DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate all DataFrames\n",
        "if dataframes:\n",
        "    df_all = pd.concat(dataframes, ignore_index=True)\n",
        "    print(f\"Merged dataset shape: {df_all.shape}\")\n",
        "    print(f\"\\nColumns: {list(df_all.columns)}\")\n",
        "    print(f\"\\nCountries: {df_all['country'].unique()}\")\n",
        "    print(f\"\\nPhases: {df_all['phase'].unique()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    df_all.head()\n",
        "else:\n",
        "    print(\"No data files found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Text Cleaning Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_urls(text):\n",
        "    \"\"\"Remove URLs from text.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # Pattern to match URLs\n",
        "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\\\\\(\\\\\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    return re.sub(url_pattern, '', str(text))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean text: convert to lowercase and remove URLs.\n",
        "    \n",
        "    Args:\n",
        "        text: Input text string\n",
        "        \n",
        "    Returns:\n",
        "        Cleaned text string\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    text = str(text)\n",
        "    text = remove_urls(text)\n",
        "    text = text.lower()\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Test the cleaning function\n",
        "test_text = \"Check out this link: https://example.com and this is UPPERCASE\"\n",
        "print(f\"Original: {test_text}\")\n",
        "print(f\"Cleaned: {clean_text(test_text)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Apply Text Cleaning and Create full_text Column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill NaN values in text columns\n",
        "df_all[\"title\"] = df_all[\"title\"].fillna(\"\")\n",
        "df_all[\"selftext\"] = df_all[\"selftext\"].fillna(\"\")\n",
        "\n",
        "# Clean title and selftext\n",
        "df_all[\"title_clean\"] = df_all[\"title\"].apply(clean_text)\n",
        "df_all[\"selftext_clean\"] = df_all[\"selftext\"].apply(clean_text)\n",
        "\n",
        "# Create full_text column (title + \" \" + selftext)\n",
        "df_all[\"full_text\"] = df_all[\"title_clean\"] + \" \" + df_all[\"selftext_clean\"]\n",
        "df_all[\"full_text\"] = df_all[\"full_text\"].str.strip()\n",
        "\n",
        "print(f\"Created full_text column\")\n",
        "print(f\"Average text length: {df_all['full_text'].str.len().mean():.1f} characters\")\n",
        "print(f\"\\nSample full_text:\")\n",
        "df_all[\"full_text\"].head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Mark Political Posts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define political keywords for each country\n",
        "POLITICAL_KEYWORDS = {\n",
        "    \"germany\": [\n",
        "        \"afd\", \"cdu\", \"spd\", \"csu\", \"gruene\", \"grüne\", \"linke\",\n",
        "        \"merz\", \"scholz\", \"habeck\", \"migration\", \"flüchtlinge\",\n",
        "        \"asyl\", \"klima\", \"heizungsgesetz\", \"bundestag\", \"ampel\"\n",
        "    ],\n",
        "    \"netherlands\": [\n",
        "        \"vvd\", \"d66\", \"pvv\", \"wilders\", \"rutte\", \"klimaat\",\n",
        "        \"immigratie\", \"verkiezingen\", \"kabinet\"\n",
        "    ],\n",
        "    \"france\": [\n",
        "        \"macron\", \"rn\", \"mélenchon\", \"melenchon\", \"immigration\",\n",
        "        \"climat\", \"gouvernement\", \"élection\", \"election\", \"assemblée\", \"assemblee\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "def is_political(text, country):\n",
        "    \"\"\"\n",
        "    Check if text contains political keywords for the given country.\n",
        "    \n",
        "    Args:\n",
        "        text: Text to check\n",
        "        country: Country name (germany, netherlands, france)\n",
        "        \n",
        "    Returns:\n",
        "        bool: True if text contains political keywords\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or text == \"\":\n",
        "        return False\n",
        "    \n",
        "    keywords = POLITICAL_KEYWORDS.get(country, [])\n",
        "    text_lower = str(text).lower()\n",
        "    \n",
        "    return any(keyword.lower() in text_lower for keyword in keywords)\n",
        "\n",
        "# Mark political posts\n",
        "df_all[\"is_political\"] = df_all.apply(\n",
        "    lambda row: is_political(row[\"full_text\"], row[\"country\"]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(f\"Political posts: {df_all['is_political'].sum()} ({df_all['is_political'].mean()*100:.1f}%)\")\n",
        "print(f\"\\nPolitical posts by country:\")\n",
        "print(df_all.groupby(\"country\")[\"is_political\"].agg([\"sum\", \"mean\"]))\n",
        "print(f\"\\nPolitical posts by phase:\")\n",
        "print(df_all.groupby(\"phase\")[\"is_political\"].agg([\"sum\", \"mean\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Summary and Quality Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert created_utc to datetime if it's a string\n",
        "if df_all[\"created_utc\"].dtype == \"object\":\n",
        "    df_all[\"created_utc\"] = pd.to_datetime(df_all[\"created_utc\"])\n",
        "\n",
        "# Create date column for easier filtering\n",
        "df_all[\"date\"] = pd.to_datetime(df_all[\"created_utc\"]).dt.date\n",
        "\n",
        "# Summary statistics\n",
        "print(\"Dataset Summary:\")\n",
        "print(f\"Total posts: {len(df_all)}\")\n",
        "print(f\"Date range: {df_all['date'].min()} to {df_all['date'].max()}\")\n",
        "print(f\"\\nPosts by country:\")\n",
        "print(df_all[\"country\"].value_counts())\n",
        "print(f\"\\nPosts by phase:\")\n",
        "print(df_all[\"phase\"].value_counts())\n",
        "print(f\"\\nPosts by country and phase:\")\n",
        "print(pd.crosstab(df_all[\"country\"], df_all[\"phase\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Export Cleaned Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select columns for final dataset\n",
        "columns_to_export = [\n",
        "    \"id\", \"title\", \"selftext\", \"title_clean\", \"selftext_clean\", \"full_text\",\n",
        "    \"author\", \"created_utc\", \"date\", \"score\", \"upvote_ratio\", \"num_comments\",\n",
        "    \"url\", \"permalink\", \"subreddit\", \"country\", \"phase\", \"is_political\",\n",
        "    \"is_self\", \"over_18\", \"source_file\"\n",
        "]\n",
        "\n",
        "# Filter to only include columns that exist\n",
        "available_columns = [col for col in columns_to_export if col in df_all.columns]\n",
        "df_clean = df_all[available_columns].copy()\n",
        "\n",
        "# Save to CSV\n",
        "output_file = DATA_CLEAN / \"all_countries_clean.csv\"\n",
        "df_clean.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"✓ Saved cleaned dataset to: {output_file}\")\n",
        "print(f\"  Shape: {df_clean.shape}\")\n",
        "print(f\"  Columns: {list(df_clean.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_clean.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Quick Visualization (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Quick visualization of data distribution\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Posts by country\n",
        "df_clean[\"country\"].value_counts().plot(kind=\"bar\", ax=axes[0], color=\"steelblue\")\n",
        "axes[0].set_title(\"Posts by Country\")\n",
        "axes[0].set_xlabel(\"Country\")\n",
        "axes[0].set_ylabel(\"Number of Posts\")\n",
        "axes[0].tick_params(axis=\"x\", rotation=45)\n",
        "\n",
        "# Political vs non-political posts\n",
        "df_clean[\"is_political\"].value_counts().plot(kind=\"bar\", ax=axes[1], color=[\"lightcoral\", \"lightgreen\"])\n",
        "axes[1].set_title(\"Political vs Non-Political Posts\")\n",
        "axes[1].set_xlabel(\"Is Political\")\n",
        "axes[1].set_ylabel(\"Number of Posts\")\n",
        "axes[1].set_xticklabels([\"Non-Political\", \"Political\"], rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nData preprocessing complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
